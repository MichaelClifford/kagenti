apiVersion: beeai.beeai.dev/v1
kind: AgentBuild
metadata:
  labels:
    app.kubernetes.io/name: kagenti-operator
  name: acp-ollama-researcher
spec:
  repoUrl: "github.com/kagenti/agent-examples.git"
  sourceSubfolder: acp/ollama-deep-researcher
  repoUser: ${REPO_USER}
  revision: "main"
  image: "acp-ollama-researcher"
  imageTag: "v0.0.1"
  imageRegistry: "ghcr.io/${REPO_USER}"
  env:
    - name: "SOURCE_REPO_SECRET"
      valueFrom:
        secretKeyRef:
          name: "github-token-secret"
          key: "token"
  deployAfterBuild: true
  cleanupAfterBuild: true
  agent:
    name: "acp-ollama-researcher"
    description: "acp-ollama-researcher from ACP community"
    env:
      - name: PORT
        value: "8000"
      - name: HOST
        value: "0.0.0.0"  
      - name: LLM_API_BASE
        value: "http://host.docker.internal:11434/v1"
      - name: LLM_API_KEY
        value: "dummy"  
      - name: LLM_MODEL
        value: "llama3.2:3b-instruct-fp16"
    resources:
      limits:
        cpu: "500m"
        memory: "1Gi"
      requests:
        cpu: "100m"
        memory: "256Mi"